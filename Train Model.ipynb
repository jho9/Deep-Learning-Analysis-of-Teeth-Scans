{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport glob\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.utils import to_categorical\n\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport random\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.applications import InceptionV3\n\nfrom tensorflow.keras import backend as K\n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import ndimage\n\n\"\"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\ntf.random.set_seed(42)\nnp.random.seed(42)\nrandom.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.metrics import Precision\nfrom tensorflow.keras.metrics import Recall\n\nfrom tensorflow.keras.metrics import TruePositives\nfrom tensorflow.keras.metrics import FalsePositives\n\nfrom tensorflow.keras.metrics import TrueNegatives\nfrom tensorflow.keras.metrics import FalseNegatives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_X_y(file_path_list, dim):\n    image_list = []\n    teeth_class = []\n    for path in file_path_list:\n        img = cv2.imread(path)\n        img = cv2.resize(img, (dim,dim)) / 255\n        image_list.append(img)\n        if path.split(\"/\")[-3] == \"Modern Teeth\":\n            teeth_class.append(0)\n        else:\n            teeth_class.append(1)\n    \n    X = np.array(image_list)\n    y = np.array(teeth_class)\n    print(np.unique(y, return_counts = True))\n    y = to_categorical(y, 2)\n    return X, y\n\n\ndef gmean(y_true, y_pred):\n    pos_score = (pos_recall(y_true, y_pred))\n    neg_score = (neg_recall(y_true, y_pred))\n    print(pos_score)\n    print(neg_score)\n    return K.sqrt(K.prod([pos_score, neg_score]))\n\ndef rotateImages(X, Y):\n    \"\"\"\n    Takes in original image and label\n    Returns array of 7 rotated arrays + labels\n    \"\"\" \n    \n    # Store rotated images and labels for appending to training\n    x_rotated = [] # lists are faster, convert after\n    y_rotated = []\n    \n    DEGREE = 45\n    \n    # Handle Singular input\n    multiple = True if len(X.shape) > 3 else False\n    \n    for idx, img in enumerate(X):\n        try:\n            y = Y[idx]\n        except:\n            y = Y\n\n        # Seven image rotations\n        for turn in range(1, 8):\n            img = img if multiple else X\n            \n            rotation = turn * DEGREE\n            r_img = ndimage.rotate(img, rotation, reshape=False)\n            \n            x_rotated.append(r_img)\n            y_rotated.append(y)\n            \n        if not multiple: break\n            \n    return np.array(x_rotated), np.array(y_rotated)\n\ndef flipImages(X, Y):\n    \"\"\"\n    Takes in original image and label\n    np.flip also flips the array sequence itself\n    So we have to flip the y-value array\n    Returns array of 2 flipped arrays + labels\n    \"\"\"\n    \n    # Flip vertically, along with labels\n    vert_flip = np.flip(X)\n    vert_flipped_labels = np.flip(Y)\n\n    # Apply to new dataset\n    new_x_train = vert_flip\n    new_y_train = vert_flipped_labels\n\n    # Flip horizontally (no need to flip labels)\n    horz_flip = np.fliplr(X)\n    \n    # Apply to dataset and return\n    new_x_train = np.concatenate((new_x_train, horz_flip))\n    new_y_train = np.concatenate((new_y_train, Y))\n    \n    return new_x_train, new_y_train\n\ndef give_simple_model(input_shape, drop_rate):\n    model = models.Sequential()\n\n    model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = input_shape))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(drop_rate, seed = 42))\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add(layers.Conv2D(16, (3,3), activation = 'relu',))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(drop_rate, seed = 42))\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add(layers.Conv2D(16, (3,3), activation = 'relu',))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(drop_rate, seed = 42))\n    model.add(layers.MaxPooling2D((2,2)))\n\n    model.add(layers.Conv2D(16, (2,2), activation = 'relu',))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(drop_rate, seed = 42))\n    model.add(layers.MaxPooling2D((2,2)))\n\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(4, activation = 'relu',))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation = 'softmax',))\n\n    #print(model.summary())\n    return model\n\ndef return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight = {0: 0.5, 1: 0.5}, augment = False, custom_model = False, verbosity = 0):\n    # Neural Network Parameters\n    input_shape = (dim, dim, 3)\n    adam = optimizers.Adam(learning_rate=lr_rate)\n    input_shape = (dim, dim, 3)\n    historical_vals = []\n    count = 1\n    for train_index, test_index in skf.split(X_place_holder, label):\n        print(count)\n        train_path_list = []\n        test_path_list = []\n\n        train_paths = list_of_images[train_index]\n        test_paths = list_of_images[test_index]\n        if custom_model == False:\n            model = give_simple_model(input_shape = input_shape, drop_rate = drop_rate)\n        elif custom_model == \"VGG16\":\n            base_vgg = VGG16(weights='imagenet', include_top = False, input_shape=input_shape)\n            last = base_vgg.layers[-2].output\n            out = GlobalAveragePooling2D()(last)\n            out = layers.Dense(128, activation='relu')(out)\n            out = layers.Dense(64, activation='relu')(out)\n            out = layers.Dense(8, activation='relu')(out)\n            #model.add(layers.Dropout(drop_rate))\n            total_classes = 2\n            predictions = layers.Dense(total_classes, activation='softmax')(out)\n\n            # Stack the two models (VGG16 and custom layers) on top of each other\n            model = Model(inputs=base_vgg.input, outputs=predictions)\n\n            # Freeze all our base_inception layers and train the last ones\n            for layer in base_vgg.layers:\n                layer.trainable = False\n        elif custom_model == \"VGG19\":\n            base_vgg = VGG19(weights='imagenet', include_top = False, input_shape=input_shape)\n            last = base_vgg.layers[-2].output\n            out = GlobalAveragePooling2D()(last)\n            out = layers.Dense(128, activation='relu')(out)\n            out = layers.Dense(64, activation='relu')(out)\n            out = layers.Dense(8, activation='relu')(out)\n            total_classes = 2\n            predictions = layers.Dense(total_classes, activation='softmax')(out)\n\n            # Stack the two models (VGG16 and custom layers) on top of each other\n            model = Model(inputs=base_vgg.input, outputs=predictions)\n\n            # Freeze all our base_inception layers and train the last ones\n            for layer in base_vgg.layers:\n                layer.trainable = False\n                \n        elif custom_model == \"ResNet50\":\n            base_vgg = ResNet50(weights='imagenet', include_top = False, input_shape=input_shape)\n            last = base_vgg.layers[-2].output\n            out = GlobalAveragePooling2D()(last)\n            out = layers.Dense(128, activation='relu')(out)\n            out = layers.Dense(64, activation='relu')(out)\n            out = layers.Dense(8, activation='relu')(out)\n            total_classes = 2\n            predictions = layers.Dense(total_classes, activation='softmax')(out)\n\n            # Stack the two models (VGG16 and custom layers) on top of each other\n            model = Model(inputs=base_vgg.input, outputs=predictions)\n\n            # Freeze all our base_inception layers and train the last ones\n            for layer in base_vgg.layers:\n                layer.trainable = False\n             \n        elif custom_model == \"Xception\":\n            base_vgg = Xception(weights='imagenet', include_top = False, input_shape=input_shape)\n            last = base_vgg.layers[-2].output\n            out = GlobalAveragePooling2D()(last)\n            out = layers.Dense(128, activation='relu')(out)\n            out = layers.Dense(64, activation='relu')(out)\n            out = layers.Dense(8, activation='relu')(out)\n            total_classes = 2\n            predictions = layers.Dense(total_classes, activation='softmax')(out)\n\n            # Stack the two models (VGG16 and custom layers) on top of each other\n            model = Model(inputs=base_vgg.input, outputs=predictions)\n\n            # Freeze all our base_inception layers and train the last ones\n            for layer in base_vgg.layers:\n                layer.trainable = False\n                \n        elif custom_model == \"InceptionV3\":\n            base_vgg = InceptionV3(weights='imagenet', include_top = False, input_shape=input_shape)\n            last = base_vgg.layers[-2].output\n            out = GlobalAveragePooling2D()(last)\n            out = layers.Dense(128, activation='relu')(out)\n            out = layers.Dense(64, activation='relu')(out)\n            out = layers.Dense(8, activation='relu')(out)\n            total_classes = 2\n            predictions = layers.Dense(total_classes, activation='softmax')(out)\n\n            # Stack the two models (VGG16 and custom layers) on top of each other\n            model = Model(inputs=base_vgg.input, outputs=predictions)\n\n            # Freeze all our base_inception layers and train the last ones\n            for layer in base_vgg.layers:\n                layer.trainable = False\n                \n        for train_path in train_paths:\n            train_path_list.extend(glob.glob(train_path + \"/*\"))    \n        for test_path in test_paths:\n            test_path_list.extend(glob.glob(test_path + \"/*\"))  \n\n        X_train, y_train = get_X_y(train_path_list, dim)\n        if augment == True:\n            x_flipped, y_flipped = flipImages(X_train, y_train)\n            x_rotated, y_rotated = rotateImages(X_train, y_train)\n            # Concat all arrays together to make one big happy array\n            X_train = np.concatenate((X_train, x_flipped, x_rotated))\n            y_train = np.concatenate((y_train, y_flipped, y_rotated))\n        \n        X_test, y_test = get_X_y(test_path_list, dim)\n\n        model.compile(optimizer=adam, \n                      loss='binary_crossentropy',\n                      metrics=['accuracy', pos_recall, neg_recall, pos_precision, neg_precision]\n                     )\n        result_gen = model.fit(X_train, y_train, batch_size = 4, epochs = epochs, verbose = verbosity, validation_data=(X_test, y_test),class_weight = class_weight)\n        curr_results = result_gen.history\n        historical_vals.append(list(curr_results.values()))\n        count = count + 1\n    result = np.mean(historical_vals, axis = 0)\n    result = pd.DataFrame(result).T\n    result.columns = list(result_gen.history.keys())\n    result['Val Geometric Mean'] = ((result['val_pos_recall']) * (result['val_neg_recall'])).apply(np.sqrt)\n    left = ((result['val_pos_recall']) * (result['val_neg_recall']) * (result['val_neg_precision'])* (result['val_pos_precision'])).apply(np.sqrt)\n    right = ((1 - (result['val_pos_recall'])) * (1 - (result['val_neg_recall'])) * (1 - (result['val_neg_precision'])) * (1 - (result['val_pos_precision']))).apply(np.sqrt)\n    result['Val MCC'] = left - right\n        \n    result = result[['val_accuracy', 'val_pos_recall','val_neg_recall', 'val_pos_precision' ,'val_neg_precision','Val Geometric Mean', 'Val MCC']]\n    return result.sort_values('Val Geometric Mean', ascending = False).round(4) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\npos_precision = Precision(thresholds=None, top_k=None, class_id=1, name='pos_precision', dtype=None)\nneg_precision = Precision(thresholds=None, top_k=None, class_id=0, name='neg_precision', dtype=None)\n\npos_recall = Recall(thresholds=None, top_k=None, class_id=1, name='pos_recall', dtype=None)\nneg_recall = Recall(thresholds=None, top_k=None, class_id=0, name='neg_recall', dtype=None)\n\nimage_path = '/kaggle/input/forensic-images/Forensic Data/Ancient Teeth/Lot 825.2/Lot 825.2 Dentin 3.tif'\npath = \"/kaggle/input/forensic-images/Forensic Data/\"\n\n#Test read and show\nimg = cv2.imread(image_path,0)\n\ndim = 256\n\n#Gets a list of unique images\nlist_of_images = []\nimage_list = []\nteeth_class = []\nmissed = 0\nfor dirpath, dirs, files in os.walk(path):\n    for filename in files:\n        list_of_images.append(dirpath)\n        \nlist_of_images = np.array(list(set(list_of_images)))\nlabel = [image.split(\"/\")[-2] for image in list_of_images]\nlabel = pd.Series(label).replace([\"Modern Teeth\", \"Ancient Teeth\"], [0, 1]).values\n\nprint(np.unique(label, return_counts = True))\n\nX_place_holder = np.ones(len(label))\n\nprint(label)\n\nneg = 25\npos = 4\ntotal = 29\n\nskf = StratifiedKFold(n_splits=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imbalance Data Reweighting"},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_for_0 = (1 / neg)*(total)/2.0 \nweight_for_1 = (1 / pos)*(total)/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_rate = 0.30\nlr_rate = 0.01\nepochs = 200","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning [Base Case Custom]"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_case = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images)\n\n#weighted base case\nsimple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight)\n\n#Augmented Data No Weights\naug_data_no_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, augment = True)\n\n#Augmented Data with Weights\naug_simple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, augment = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_case.to_csv(\"Base_Custom_NoWeights.csv\",index=True)\nsimple_weights.to_csv(\"Base_Custom_Weights.csv\",index=True)\naug_data_no_weights.to_csv(\"Aug_Custom_NoWeights.csv\",index=True)\naug_simple_weights.to_csv(\"Aug_Custom_Weights.csv\",index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning [VGG16]"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Base Case\nbase_case = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, custom_model = \"VGG16\")\n\n#Weighted base case\nsimple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, custom_model = 'VGG16')\n\n#Augmented Data No Weights\naug_data_no_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, augment = True, custom_model = 'VGG16')\n\n#Data with Weights\ntrans_aug_simple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, augment = True, custom_model = 'VGG16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_case.to_csv(\"VGG16_NoWeights.csv\",index=True)\nsimple_weights.to_csv(\"VGG16_Weights.csv\",index=True)\naug_data_no_weights.to_csv(\"Aug_VGG16_NoWeights.csv\",index=True)\naug_simple_weights.to_csv(\"Aug_VGG16_Weights.csv\",index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning [VGG19]"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Base Case\nbase_case = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, custom_model = \"VGG19\", verbosity = 0)\n\n#Weighted base case\nsimple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, custom_model = 'VGG19')\n\n#Augmented Data No Weights\naug_data_no_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, augment = True, custom_model = 'VGG19')\n\n#Data with Weights\ntrans_aug_simple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, augment = True, custom_model = 'VGG19')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_case.to_csv(\"VGG19_NoWeights.csv\",index=True)\nsimple_weights.to_csv(\"VGG19_Weights.csv\",index=True)\naug_data_no_weights.to_csv(\"Aug_VGG19_NoWeights.csv\",index=True)\naug_simple_weights.to_csv(\"Aug_VGG19_Weights.csv\",index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning [ResNet50]"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Base Case\nbase_case = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, custom_model = \"ResNet50\", verbosity = 0)\n\n#Weighted base case\nsimple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, custom_model = 'ResNet50')\n\n#Augmented Data No Weights\naug_data_no_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, augment = True, custom_model = 'ResNet50')\n\n#Data with Weights\ntrans_aug_simple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, augment = True, custom_model = 'ResNet50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_case.to_csv(\"ResNet50_NoWeights.csv\",index=True)\nsimple_weights.to_csv(\"ResNet50_Weights.csv\",index=True)\naug_data_no_weights.to_csv(\"Aug_ResNet50_NoWeights.csv\",index=True)\naug_simple_weights.to_csv(\"Aug_ResNet50_Weights.csv\",index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning [Xception]"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Base Case\nbase_case = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, custom_model = \"Xception\", verbosity = 0)\n\n#Weighted base case\nsimple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, custom_model = 'Xception', verbosity = 0)\n\n#Augmented Data No Weights\naug_data_no_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, augment = True, custom_model = 'Xception', verbosity = 0)\n\n#Data with Weights\ntrans_aug_simple_weights = return_results(drop_rate, dim, lr_rate, epochs, X_place_holder, label, list_of_images, class_weight, augment = True, custom_model = 'Xception', verbosity = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_case.to_csv(\"Xception_NoWeights.csv\",index=True)\nsimple_weights.to_csv(\"Xception_Weights.csv\",index=True)\naug_data_no_weights.to_csv(\"Aug_Xception_NoWeights.csv\",index=True)\naug_simple_weights.to_csv(\"Aug_Xception_Weights.csv\",index=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}